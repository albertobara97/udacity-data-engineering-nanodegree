{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df43137509eb68088699105a61565dad871be4f70351b14b46e26560cb30e335"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Capstone project - Analytics in agriculture\n",
    "\n",
    "### In this file, we can find the ETL process that our project follows to go from the raw data located in 'data/' to the curated data stored in our rdbms. For this first version the rdbms will be PostgreSQL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "import pandas as pd\n",
    "import time\n",
    "import configparser\n",
    "import json"
   ]
  },
  {
   "source": [
    "# 1. Extraction\n",
    "\n",
    "### We are not starting from the very first stage. The extraction phase begins when downloading the data from the database, but since this first step needs to be done yearly due to de refresh schedule that this data is following, we did a manual step before the one described below (Manual step: download files > uncompress files)\n",
    "\n",
    "### After the short explanation, we proceed with the extraction of the data. The data that our source provides are csv files. Since, the data is completely untouched, we will need to select the files/tables that are useful for our project and rearrange the structure of the columns because as we will see during the etl, the structure given is optimized for storage but not for a more advanced data model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Alberto\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3155: DtypeWarning: Columns (8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "crops_data = pd.read_csv(\"data/Production_Crops_E_All_Data.csv\", encoding=\"ANSI\")\n",
    "trade_data = pd.read_csv(\"data/Trade_Crops_Livestock_E_All_Data.csv\", encoding=\"ANSI\")\n",
    "crops_flags = pd.read_csv(\"data/Production_Crops_E_Flags.csv\", encoding=\"ANSI\")\n",
    "trade_flags = pd.read_csv(\"data/Trade_Crops_Livestock_E_Flags.csv\", encoding=\"ANSI\")\n",
    "\n",
    "with open(\"credentials/redshift.json\", 'r') as j:\n",
    "    redshift = json.loads(j.read())\n",
    "\n",
    "# Deletes temporary variable j\n",
    "del j"
   ]
  },
  {
   "source": [
    "# 2. Transformation\n",
    "\n",
    "## Creation of dimension tables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_countries = crops_data[[\"Area Code\", \"Area\"]].append(trade_data[[\"Area Code\", \"Area\"]]).drop_duplicates()\n",
    "dim_items = crops_data[[\"Item Code\", \"Item\"]].drop_duplicates()\n",
    "dim_elements = crops_data[[\"Element Code\", \"Element\"]].append(trade_data[[\"Element Code\", \"Element\"]]).drop_duplicates()\n",
    "dim_flags = crops_flags.append(trade_flags).drop_duplicates()\n",
    "\n",
    "#Delete original flags dataframes\n",
    "del crops_flags, trade_flags"
   ]
  },
  {
   "source": [
    "## Clean dataframes\n",
    "\n",
    "### Trade data has mixed crops and products data. to increase the performance of the next steps, first we will need to remove the rows that are not crops.\n",
    "\n",
    "### Dimensions contain lots of duplciated data, therefore they will be trimmed as well"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = trade_data[trade_data[\"Item Code\"].isin(dim_items[\"Item Code\"])]\n",
    "#temp_items = trade_data[\"Item\"].drop_duplicates()\n",
    "#temp_items"
   ]
  },
  {
   "source": [
    "## Modify Flags dataframe\n",
    "\n",
    "### Flags table has \"blank\" primary key string associated to \"Official data\", but in the  fact table the value is blank. So it is needed to change the string \"blank\" to a blank string"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_flags = dim_flags.replace(\"<blank>\", \"\")"
   ]
  },
  {
   "source": [
    "## rearrange the dataframe structures and creation of the fact table\n",
    "\n",
    "### The design of this structure, will make the data grow horizontally, but for our SQL schema we can't keep a schema that is growing into this direction, so to rearrange the tables we have divided the data into 2 groups: keys and values. \n",
    "* keys: data that will be repeated after each iteration and serves as an identifier for the values\n",
    "* values: data reported yearly and makes the dataframe grow each year 2 columns more"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "evaluated from crops_data:  Y1961\n",
      "evaluated from crops_data:  Y1962\n",
      "evaluated from crops_data:  Y1963\n",
      "evaluated from crops_data:  Y1964\n",
      "evaluated from crops_data:  Y1965\n",
      "evaluated from crops_data:  Y1966\n",
      "evaluated from crops_data:  Y1967\n",
      "evaluated from crops_data:  Y1968\n",
      "evaluated from crops_data:  Y1969\n",
      "evaluated from crops_data:  Y1970\n",
      "evaluated from crops_data:  Y1971\n",
      "evaluated from crops_data:  Y1972\n",
      "evaluated from crops_data:  Y1973\n",
      "evaluated from crops_data:  Y1974\n",
      "evaluated from crops_data:  Y1975\n",
      "evaluated from crops_data:  Y1976\n",
      "evaluated from crops_data:  Y1977\n",
      "evaluated from crops_data:  Y1978\n",
      "evaluated from crops_data:  Y1979\n",
      "evaluated from crops_data:  Y1980\n",
      "evaluated from crops_data:  Y1981\n",
      "evaluated from crops_data:  Y1982\n",
      "evaluated from crops_data:  Y1983\n",
      "evaluated from crops_data:  Y1984\n",
      "evaluated from crops_data:  Y1985\n",
      "evaluated from crops_data:  Y1986\n",
      "evaluated from crops_data:  Y1987\n",
      "evaluated from crops_data:  Y1988\n",
      "evaluated from crops_data:  Y1989\n",
      "evaluated from crops_data:  Y1990\n",
      "evaluated from crops_data:  Y1991\n",
      "evaluated from crops_data:  Y1992\n",
      "evaluated from crops_data:  Y1993\n",
      "evaluated from crops_data:  Y1994\n",
      "evaluated from crops_data:  Y1995\n",
      "evaluated from crops_data:  Y1996\n",
      "evaluated from crops_data:  Y1997\n",
      "evaluated from crops_data:  Y1998\n",
      "evaluated from crops_data:  Y1999\n",
      "evaluated from crops_data:  Y2000\n",
      "evaluated from crops_data:  Y2001\n",
      "evaluated from crops_data:  Y2002\n",
      "evaluated from crops_data:  Y2003\n",
      "evaluated from crops_data:  Y2004\n",
      "evaluated from crops_data:  Y2005\n",
      "evaluated from crops_data:  Y2006\n",
      "evaluated from crops_data:  Y2007\n",
      "evaluated from crops_data:  Y2008\n",
      "evaluated from crops_data:  Y2009\n",
      "evaluated from crops_data:  Y2010\n",
      "evaluated from crops_data:  Y2011\n",
      "evaluated from crops_data:  Y2012\n",
      "evaluated from crops_data:  Y2013\n",
      "evaluated from crops_data:  Y2014\n",
      "evaluated from crops_data:  Y2015\n",
      "evaluated from crops_data:  Y2016\n",
      "evaluated from crops_data:  Y2017\n",
      "evaluated from crops_data:  Y2018\n",
      "evaluated from crops_data:  Y2019\n",
      "evaluated from trade_data:  Y1961\n",
      "evaluated from trade_data:  Y1962\n",
      "evaluated from trade_data:  Y1963\n",
      "evaluated from trade_data:  Y1964\n",
      "evaluated from trade_data:  Y1965\n",
      "evaluated from trade_data:  Y1966\n",
      "evaluated from trade_data:  Y1967\n",
      "evaluated from trade_data:  Y1968\n",
      "evaluated from trade_data:  Y1969\n",
      "evaluated from trade_data:  Y1970\n",
      "evaluated from trade_data:  Y1971\n",
      "evaluated from trade_data:  Y1972\n",
      "evaluated from trade_data:  Y1973\n",
      "evaluated from trade_data:  Y1974\n",
      "evaluated from trade_data:  Y1975\n",
      "evaluated from trade_data:  Y1976\n",
      "evaluated from trade_data:  Y1977\n",
      "evaluated from trade_data:  Y1978\n",
      "evaluated from trade_data:  Y1979\n",
      "evaluated from trade_data:  Y1980\n",
      "evaluated from trade_data:  Y1981\n",
      "evaluated from trade_data:  Y1982\n",
      "evaluated from trade_data:  Y1983\n",
      "evaluated from trade_data:  Y1984\n",
      "evaluated from trade_data:  Y1985\n",
      "evaluated from trade_data:  Y1986\n",
      "evaluated from trade_data:  Y1987\n",
      "evaluated from trade_data:  Y1988\n",
      "evaluated from trade_data:  Y1989\n",
      "evaluated from trade_data:  Y1990\n",
      "evaluated from trade_data:  Y1991\n",
      "evaluated from trade_data:  Y1992\n",
      "evaluated from trade_data:  Y1993\n",
      "evaluated from trade_data:  Y1994\n",
      "evaluated from trade_data:  Y1995\n",
      "evaluated from trade_data:  Y1996\n",
      "evaluated from trade_data:  Y1997\n",
      "evaluated from trade_data:  Y1998\n",
      "evaluated from trade_data:  Y1999\n",
      "evaluated from trade_data:  Y2000\n",
      "evaluated from trade_data:  Y2001\n",
      "evaluated from trade_data:  Y2002\n",
      "evaluated from trade_data:  Y2003\n",
      "evaluated from trade_data:  Y2004\n",
      "evaluated from trade_data:  Y2005\n",
      "evaluated from trade_data:  Y2006\n",
      "evaluated from trade_data:  Y2007\n",
      "evaluated from trade_data:  Y2008\n",
      "evaluated from trade_data:  Y2009\n",
      "evaluated from trade_data:  Y2010\n",
      "evaluated from trade_data:  Y2011\n",
      "evaluated from trade_data:  Y2012\n",
      "evaluated from trade_data:  Y2013\n",
      "evaluated from trade_data:  Y2014\n",
      "evaluated from trade_data:  Y2015\n",
      "evaluated from trade_data:  Y2016\n",
      "evaluated from trade_data:  Y2017\n",
      "evaluated from trade_data:  Y2018\n",
      "evaluated from trade_data:  Y2019\n",
      "elapsed time:  72.920001745224\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "raw_crop_keys = crops_data[[\"Area Code\", \"Item Code\", \"Element Code\", \"Unit\"]]\n",
    "raw_crop_values = crops_data.drop(labels = [\"Area Code\", \"Area\", \"Item Code\", \"Item\", \"Element Code\", \"Element\", \"Unit\"], axis = 1)\n",
    "\n",
    "raw_trade_keys = trade_data[[\"Area Code\", \"Item Code\", \"Element Code\", \"Unit\"]]\n",
    "raw_trade_values = trade_data.drop(labels = [\"Area Code\", \"Area\", \"Item Code\", \"Item\", \"Element Code\", \"Element\", \"Unit\"], axis = 1)\n",
    "\n",
    "if(len(raw_crop_values.columns) % 2 == 1):\n",
    "    print(raw_crop_values.columns)\n",
    "    raise Exception(\"Unexpected column found, columns number must be even as they consist of pairs. Please check out the dataframe structure\")\n",
    "\n",
    "if(len(raw_trade_values.columns) % 2 == 1):\n",
    "    print(raw_trade_values.columns)\n",
    "    raise Exception(\"Unexpected column found, columns number must be even as they consist of pairs. Please check out the dataframe structure\")\n",
    "\n",
    "fact_crops_data = pd.DataFrame(columns = [\"Area Code\", \"Item Code\", \"Element Code\", \"Unit\", \"Year\", \"Value\", \"Flag\"])\n",
    "\n",
    "fact_trade_data = pd.DataFrame(columns = [\"Area Code\", \"Item Code\", \"Element Code\", \"Unit\", \"Year\", \"Value\", \"Flag\"])\n",
    "\n",
    "for A, B in zip(*[iter(raw_crop_values)]*2):\n",
    "    temp_aux_crops = raw_crop_keys.append(raw_crop_values[[A, B]]).rename(columns = {A: \"Value\", B: \"Flag\"})\n",
    "    print(\"evaluated from crops_data: \", A)\n",
    "    fact_crops_data = fact_crops_data.append(temp_aux_crops)\n",
    "\n",
    "for A, B in zip(*[iter(raw_trade_values)]*2):\n",
    "    temp_aux_trade = raw_trade_keys.append(raw_trade_values[[A, B]]).rename(columns = {A: \"Value\", B: \"Flag\"})\n",
    "    print(\"evaluated from trade_data: \", A)\n",
    "    fact_trade_data = fact_trade_data.append(temp_aux_trade)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# Delete temporary variables\n",
    "del A, B, raw_crop_keys, raw_crop_values, raw_trade_keys, raw_trade_values\n",
    "\n",
    "# Delete original dataframes\n",
    "del crops_data, trade_data\n",
    "\n",
    "print(\"elapsed time: \", end - start)\n",
    "\n",
    "# Delete chrono temporary variables\n",
    "del start, end"
   ]
  },
  {
   "source": [
    "# 3. Load\n",
    "\n",
    "## Load the tables into our redshift cluster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(f\"host={redshift['endpoint']} dbname={redshift['database']} user={redshift['username']} password={redshift['password']} port={redshift['port']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"SET AUTOCOMMIT = TRUE;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('dev', 'public', 'items', 'BASE TABLE', None, None, None, None, None)\n('dev', 'public', 'flags', 'BASE TABLE', None, None, None, None, None)\n('dev', 'public', 'elements', 'BASE TABLE', None, None, None, None, None)\n('dev', 'public', 'countries', 'BASE TABLE', None, None, None, None, None)\n('dev', 'public', 'fact_trade', 'BASE TABLE', None, None, None, None, None)\n('dev', 'public', 'fact_crops', 'BASE TABLE', None, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT * FROM information_schema.tables WHERE table_schema = 'public'\")\n",
    "for row in cur.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Delete temporary value\n",
    "del row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY EXECUTE IF DATA IS WRONG\n",
    "\n",
    "cur.execute(\"DROP TABLE IF EXISTS countries, elements, flags, items, fact_crops, fact_trade;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crops fact table if not exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fact_crops(\n",
    "        Area_code int not null,\n",
    "        Item_Code int not null,\n",
    "        Element_Code int not null,\n",
    "        Unit varchar(50),\n",
    "        Year int not null,\n",
    "        Value float,\n",
    "        Flag varchar(25)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Create trade fact table if not exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fact_trade(\n",
    "        Area_code int not null,\n",
    "        Item_Code int not null,\n",
    "        Element_Code int not null,\n",
    "        Unit varchar(50),\n",
    "        Year int not null,\n",
    "        Value float,\n",
    "        Flag varchar(25)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Create Countries dimension table if not exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS countries(\n",
    "        Area_Code int not null UNIQUE PRIMARY KEY,\n",
    "        Area varchar(100)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Create Elements dimension table if not exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS elements(\n",
    "        Element_Code int not null UNIQUE PRIMARY KEY,\n",
    "        Element varchar(100)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Create Flags dimension table if not exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS flags(\n",
    "        Flag varchar(25) UNIQUE PRIMARY KEY,\n",
    "        Description varchar(100)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Create Items dimension table if not exists\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS items(\n",
    "        Item_Code int not null UNIQUE PRIMARY KEY,\n",
    "        Item varchar(100)\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    psycopg2.extras.execute_values(cur, \"INSERT INTO countries VALUES %s;\", dim_countries.itertuples(index=False))\n",
    "    \n",
    "    psycopg2.extras.execute_values(cur, \"INSERT INTO flags VALUES %s\", dim_flags.itertuples(index=False))\n",
    "\n",
    "    psycopg2.extras.execute_values(cur, \"INSERT INTO elements VALUES %s\", dim_elements.itertuples(index=False))\n",
    "\n",
    "    psycopg2.extras.execute_values(cur, \"INSERT INTO items VALUES %s\", dim_items.itertuples(index=False))\n",
    "\n",
    "    psycopg2.extras.execute_values(cur, \"INSERT INTO fact_crops VALUES %s\", fact_crops_data.itertuples(index=False))\n",
    "\n",
    "    psycopg2.extras.execute_values(cur, \"INSERT INTO fact_trade VALUES %s\", fact_trade_data.itertuples(index=False))\n",
    "\n",
    "except: \n",
    "    conn.rollback()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"elapsed time: \", end - start)\n",
    "\n",
    "# Delete chrono temporary variables\n",
    "del start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 'Afghanistan')\n(3, 'Albania')\n(4, 'Algeria')\n(7, 'Angola')\n(8, 'Antigua and Barbuda')\n(9, 'Argentina')\n(1, 'Armenia')\n(10, 'Australia')\n(11, 'Austria')\n(52, 'Azerbaijan')\n(12, 'Bahamas')\n(13, 'Bahrain')\n(16, 'Bangladesh')\n(14, 'Barbados')\n(57, 'Belarus')\n(255, 'Belgium')\n(15, 'Belgium-Luxembourg')\n(23, 'Belize')\n(53, 'Benin')\n(18, 'Bhutan')\n(19, 'Bolivia (Plurinational State of)')\n(80, 'Bosnia and Herzegovina')\n(20, 'Botswana')\n(21, 'Brazil')\n(26, 'Brunei Darussalam')\n(27, 'Bulgaria')\n(233, 'Burkina Faso')\n(29, 'Burundi')\n(35, 'Cabo Verde')\n(115, 'Cambodia')\n(32, 'Cameroon')\n(33, 'Canada')\n(37, 'Central African Republic')\n(39, 'Chad')\n(40, 'Chile')\n(351, 'China')\n(96, 'China, Hong Kong SAR')\n(128, 'China, Macao SAR')\n(41, 'China, mainland')\n(214, 'China, Taiwan Province of')\n(44, 'Colombia')\n(45, 'Comoros')\n(46, 'Congo')\n(47, 'Cook Islands')\n(48, 'Costa Rica')\n(107, \"Côte d'Ivoire\")\n(98, 'Croatia')\n(49, 'Cuba')\n(50, 'Cyprus')\n(167, 'Czechia')\n(51, 'Czechoslovakia')\n(116, \"Democratic People's Republic of Korea\")\n(250, 'Democratic Republic of the Congo')\n(54, 'Denmark')\n(72, 'Djibouti')\n(55, 'Dominica')\n(56, 'Dominican Republic')\n(58, 'Ecuador')\n(59, 'Egypt')\n(60, 'El Salvador')\n(61, 'Equatorial Guinea')\n(178, 'Eritrea')\n(63, 'Estonia')\n(209, 'Eswatini')\n(238, 'Ethiopia')\n(62, 'Ethiopia PDR')\n(64, 'Faroe Islands')\n(66, 'Fiji')\n(67, 'Finland')\n(68, 'France')\n(69, 'French Guyana')\n(70, 'French Polynesia')\n(74, 'Gabon')\n(75, 'Gambia')\n(73, 'Georgia')\n(79, 'Germany')\n(81, 'Ghana')\n(84, 'Greece')\n(86, 'Grenada')\n(87, 'Guadeloupe')\n(89, 'Guatemala')\n(90, 'Guinea')\n(175, 'Guinea-Bissau')\n(91, 'Guyana')\n(93, 'Haiti')\n(95, 'Honduras')\n(97, 'Hungary')\n(99, 'Iceland')\n(100, 'India')\n(101, 'Indonesia')\n(102, 'Iran (Islamic Republic of)')\n(103, 'Iraq')\n(104, 'Ireland')\n(105, 'Israel')\n(106, 'Italy')\n(109, 'Jamaica')\n(110, 'Japan')\n(112, 'Jordan')\n(108, 'Kazakhstan')\n(114, 'Kenya')\n(83, 'Kiribati')\n(118, 'Kuwait')\n(113, 'Kyrgyzstan')\n(120, \"Lao People's Democratic Republic\")\n(119, 'Latvia')\n(121, 'Lebanon')\n(122, 'Lesotho')\n(123, 'Liberia')\n(124, 'Libya')\n(126, 'Lithuania')\n(256, 'Luxembourg')\n(129, 'Madagascar')\n(130, 'Malawi')\n(131, 'Malaysia')\n(132, 'Maldives')\n(133, 'Mali')\n(134, 'Malta')\n(127, 'Marshall Islands')\n(135, 'Martinique')\n(136, 'Mauritania')\n(137, 'Mauritius')\n(138, 'Mexico')\n(145, 'Micronesia (Federated States of)')\n(141, 'Mongolia')\n(273, 'Montenegro')\n(143, 'Morocco')\n(144, 'Mozambique')\n(28, 'Myanmar')\n(147, 'Namibia')\n(148, 'Nauru')\n(149, 'Nepal')\n(150, 'Netherlands')\n(153, 'New Caledonia')\n(156, 'New Zealand')\n(157, 'Nicaragua')\n(158, 'Niger')\n(159, 'Nigeria')\n(160, 'Niue')\n(154, 'North Macedonia')\n(162, 'Norway')\n(221, 'Oman')\n(165, 'Pakistan')\n(299, 'Palestine')\n(166, 'Panama')\n(168, 'Papua New Guinea')\n(169, 'Paraguay')\n(170, 'Peru')\n(171, 'Philippines')\n(173, 'Poland')\n(174, 'Portugal')\n(177, 'Puerto Rico')\n(179, 'Qatar')\n(117, 'Republic of Korea')\n(146, 'Republic of Moldova')\n(182, 'Réunion')\n(183, 'Romania')\n(185, 'Russian Federation')\n(184, 'Rwanda')\n(188, 'Saint Kitts and Nevis')\n(189, 'Saint Lucia')\n(191, 'Saint Vincent and the Grenadines')\n(244, 'Samoa')\n(193, 'Sao Tome and Principe')\n(194, 'Saudi Arabia')\n(195, 'Senegal')\n(272, 'Serbia')\n(186, 'Serbia and Montenegro')\n(196, 'Seychelles')\n(197, 'Sierra Leone')\n(200, 'Singapore')\n(199, 'Slovakia')\n(198, 'Slovenia')\n(25, 'Solomon Islands')\n(201, 'Somalia')\n(202, 'South Africa')\n(277, 'South Sudan')\n(203, 'Spain')\n(38, 'Sri Lanka')\n(276, 'Sudan')\n(206, 'Sudan (former)')\n(207, 'Suriname')\n(210, 'Sweden')\n(211, 'Switzerland')\n(212, 'Syrian Arab Republic')\n(208, 'Tajikistan')\n(216, 'Thailand')\n(176, 'Timor-Leste')\n(217, 'Togo')\n(218, 'Tokelau')\n(219, 'Tonga')\n(220, 'Trinidad and Tobago')\n(222, 'Tunisia')\n(223, 'Turkey')\n(213, 'Turkmenistan')\n(227, 'Tuvalu')\n(226, 'Uganda')\n(230, 'Ukraine')\n(225, 'United Arab Emirates')\n(229, 'United Kingdom of Great Britain and Northern Ireland')\n(215, 'United Republic of Tanzania')\n(231, 'United States of America')\n(234, 'Uruguay')\n(228, 'USSR')\n(235, 'Uzbekistan')\n(155, 'Vanuatu')\n(236, 'Venezuela (Bolivarian Republic of)')\n(237, 'Viet Nam')\n(249, 'Yemen')\n(248, 'Yugoslav SFR')\n(251, 'Zambia')\n(181, 'Zimbabwe')\n(5000, 'World')\n(5100, 'Africa')\n(5101, 'Eastern Africa')\n(5102, 'Middle Africa')\n(5103, 'Northern Africa')\n(5104, 'Southern Africa')\n(5105, 'Western Africa')\n(5200, 'Americas')\n(5203, 'Northern America')\n(5204, 'Central America')\n(5206, 'Caribbean')\n(5207, 'South America')\n(5300, 'Asia')\n(5301, 'Central Asia')\n(5302, 'Eastern Asia')\n(5303, 'Southern Asia')\n(5304, 'South-eastern Asia')\n(5305, 'Western Asia')\n(5400, 'Europe')\n(5401, 'Eastern Europe')\n(5402, 'Northern Europe')\n(5403, 'Southern Europe')\n(5404, 'Western Europe')\n(5500, 'Oceania')\n(5501, 'Australia and New Zealand')\n(5502, 'Melanesia')\n(5503, 'Micronesia')\n(5504, 'Polynesia')\n(5706, 'European Union (28)')\n(5707, 'European Union (27)')\n(5801, 'Least Developed Countries')\n(5802, 'Land Locked Developing Countries')\n(5803, 'Small Island Developing States')\n(5815, 'Low Income Food Deficit Countries')\n(5817, 'Net Food Importing Developing Countries')\n(265, 'China (excluding intra-trade)')\n(51000, 'Africa (excluding intra-trade)')\n(51010, 'Eastern Africa (excluding intra-trade)')\n(51020, 'Middle Africa (excluding intra-trade)')\n(51030, 'Northern Africa (excluding intra-trade)')\n(51040, 'Southern Africa (excluding intra-trade)')\n(51050, 'Western Africa (excluding intra-trade)')\n(52000, 'Americas (excluding intra-trade)')\n(52030, 'Northern America (excluding intra-trade)')\n(52040, 'Central America (excluding intra-trade)')\n(52060, 'Caribbean (excluding intra-trade)')\n(52070, 'South America (excluding intra-trade)')\n(53000, 'Asia (excluding intra-trade)')\n(53010, 'Central Asia (excluding intra-trade)')\n(53020, 'Eastern Asia (excluding intra-trade)')\n(53030, 'Southern Asia (excluding intra-trade)')\n(53040, 'South-Eastern Asia (excluding intra-trade)')\n(53050, 'Western Asia (excluding intra-trade)')\n(54000, 'Europe (excluding intra-trade)')\n(54010, 'Eastern Europe (excluding intra-trade)')\n(54020, 'Northern Europe (excluding intra-trade)')\n(54030, 'Southern Europe (excluding intra-trade)')\n(54040, 'Western Europe (excluding intra-trade)')\n(55000, 'Oceania (excluding intra-trade)')\n(55010, 'Australia and New Zealand (excluding intra-trade)')\n(55020, 'Melanesia (excluding intra-trade)')\n(55030, 'Micronesia (excluding intra-trade)')\n(55040, 'Polynesia (excluding intra-trade)')\n(261, 'European Union (12) (excluding intra-trade)')\n(266, 'European Union (15) (excluding intra-trade)')\n(268, 'European Union (25) (excluding intra-trade)')\n(57070, 'European Union (27) (excluding intra-trade)')\n(57060, 'European Union (28) (excluding intra-trade)')\n(58010, 'Least Developed Countries (excluding intra-trade)')\n(58020, 'Land Locked Developing Countries (excluding intra-trade)')\n(58030, 'Small Island Developing States (excluding intra-trade)')\n(58150, 'Low Income Food Deficit Countries (excluding intra-trade)')\n(58170, 'Net Food Importing Developing Countries (excluding intra-trade)')\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT * FROM countries;\")\n",
    "for row in cur.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Delete temporary value\n",
    "del row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('area_code', 'integer', None, None, 'NO')\n('area', 'character varying', 100, None, 'YES')\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT \n",
    "        column_name, data_type, character_maximum_length, column_default, is_nullable\n",
    "    FROM \n",
    "        information_schema.columns\n",
    "    WHERE \n",
    "        table_name = 'countries';\n",
    "\"\"\")\n",
    "for row in cur.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Delete temporary value\n",
    "del row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}